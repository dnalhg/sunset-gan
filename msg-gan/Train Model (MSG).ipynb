{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcaa03ff6f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1 # random.randint(1, 10000)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data configs\n",
    "IMG_DIR = \"../training_images/\"\n",
    "BATCH_SIZE = 8\n",
    "DLOADER_WORKERS = 0\n",
    "\n",
    "# Model configs\n",
    "DEPTH = 6 # Final image size is 2**DEPTH\n",
    "LATENT_SIZE = 512 # Size of the input latent space\n",
    "\n",
    "# Optimiser configs\n",
    "G_LR = 0.0001\n",
    "D_LR = 0.0003\n",
    "BETA1 = 0\n",
    "BETA2 = 0.999\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader\n",
    "dataloader = create_dataloader(IMG_DIR, BATCH_SIZE, DLOADER_WORKERS, DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MSG_GAN import MSG_GAN\n",
    "from loss import StandardGAN\n",
    "\n",
    "model = MSG_GAN(DEPTH, LATENT_SIZE)\n",
    "g_optim = torch.optim.Adam(model.gen.parameters(), G_LR, [BETA1, BETA2])\n",
    "d_optim = torch.optim.Adam(model.dis.parameters(), D_LR, [BETA1, BETA2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load saved model if possible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0\n",
    "TOTAL_EPOCH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f\"{START_EPOCH}_save.pt\")\n",
    "model.gen.load_state_dict(checkpoint[\"gen\"])\n",
    "model.dis.load_state_dict(checkpoint[\"dis\"])\n",
    "g_optim.load_state_dict(checkpoint[\"gen_optim\"])\n",
    "d_optim.load_state_dict(checkpoint[\"dis_optim\"])\n",
    "model.gen_shadow.load_state_dict(checkpoint[\"gen_shadow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Elapsed [0:00:19.595205] batch: 40  d_loss: 0.178612  g_loss: 3.818853\n",
      "Elapsed [0:00:39.407569] batch: 80  d_loss: 0.298625  g_loss: 3.387247\n",
      "Elapsed [0:00:57.112386] batch: 120  d_loss: 0.205006  g_loss: 3.442460\n",
      "Elapsed [0:01:16.354863] batch: 160  d_loss: 0.191966  g_loss: 3.814625\n",
      "Elapsed [0:01:35.355829] batch: 200  d_loss: 0.172132  g_loss: 4.739140\n",
      "Elapsed [0:01:52.868155] batch: 240  d_loss: 0.192985  g_loss: 4.728215\n",
      "Elapsed [0:02:10.616658] batch: 280  d_loss: 0.168022  g_loss: 4.488097\n",
      "Elapsed [0:02:29.348290] batch: 320  d_loss: 0.204518  g_loss: 4.982589\n",
      "Elapsed [0:02:48.044660] batch: 360  d_loss: 0.163147  g_loss: 7.086243\n",
      "Time taken for epoch: 179.969 secs\n",
      "\n",
      "Epoch: 2\n",
      "Elapsed [0:03:17.908164] batch: 40  d_loss: 0.181761  g_loss: 4.062128\n",
      "Elapsed [0:03:36.516981] batch: 80  d_loss: 0.174177  g_loss: 4.045695\n",
      "Elapsed [0:03:55.032966] batch: 120  d_loss: 0.165330  g_loss: 5.662098\n",
      "Elapsed [0:04:14.302273] batch: 160  d_loss: 0.166445  g_loss: 6.174897\n",
      "Elapsed [0:04:32.126317] batch: 200  d_loss: 0.213945  g_loss: 5.396828\n",
      "Elapsed [0:04:49.808055] batch: 240  d_loss: 0.164628  g_loss: 5.051711\n",
      "Elapsed [0:05:07.507795] batch: 280  d_loss: 0.170432  g_loss: 5.081217\n",
      "Elapsed [0:05:26.383160] batch: 320  d_loss: 0.185590  g_loss: 5.036038\n",
      "Elapsed [0:05:44.260993] batch: 360  d_loss: 0.167755  g_loss: 4.480678\n",
      "Time taken for epoch: 177.104 secs\n",
      "\n",
      "Epoch: 3\n",
      "Elapsed [0:06:15.375558] batch: 40  d_loss: 0.164926  g_loss: 5.099514\n",
      "Elapsed [0:06:33.458922] batch: 80  d_loss: 0.168904  g_loss: 5.441385\n",
      "Elapsed [0:06:51.719558] batch: 120  d_loss: 0.183614  g_loss: 4.983022\n",
      "Elapsed [0:07:09.357680] batch: 160  d_loss: 0.164620  g_loss: 5.571464\n",
      "Elapsed [0:07:27.510588] batch: 200  d_loss: 0.163047  g_loss: 6.665353\n",
      "Elapsed [0:07:45.676353] batch: 240  d_loss: 0.166973  g_loss: 4.768822\n",
      "Elapsed [0:08:05.166277] batch: 280  d_loss: 0.173168  g_loss: 4.201189\n",
      "Elapsed [0:08:24.750518] batch: 320  d_loss: 0.169192  g_loss: 4.251176\n",
      "Elapsed [0:08:42.698244] batch: 360  d_loss: 0.174534  g_loss: 7.034103\n",
      "Time taken for epoch: 177.616 secs\n",
      "\n",
      "Epoch: 4\n",
      "Elapsed [0:09:12.327868] batch: 40  d_loss: 0.188932  g_loss: 3.724636\n",
      "Elapsed [0:09:30.032227] batch: 80  d_loss: 0.169085  g_loss: 4.674007\n",
      "Elapsed [0:09:47.732661] batch: 120  d_loss: 0.163267  g_loss: 5.994493\n",
      "Elapsed [0:10:06.952736] batch: 160  d_loss: 0.178695  g_loss: 4.903131\n",
      "Elapsed [0:10:25.836444] batch: 200  d_loss: 0.179999  g_loss: 4.520282\n",
      "Elapsed [0:10:44.379439] batch: 240  d_loss: 0.162896  g_loss: 6.605268\n",
      "Elapsed [0:11:03.338791] batch: 280  d_loss: 0.176025  g_loss: 7.811156\n",
      "Elapsed [0:11:21.176184] batch: 320  d_loss: 0.181053  g_loss: 4.379816\n",
      "Elapsed [0:11:39.339877] batch: 360  d_loss: 0.193458  g_loss: 4.060015\n",
      "Time taken for epoch: 177.349 secs\n",
      "\n",
      "Epoch: 5\n",
      "Elapsed [0:12:10.746234] batch: 40  d_loss: 0.166285  g_loss: 6.832101\n",
      "Elapsed [0:12:29.235856] batch: 80  d_loss: 0.165920  g_loss: 5.558976\n",
      "Elapsed [0:12:47.249985] batch: 120  d_loss: 0.166521  g_loss: 5.292618\n",
      "Elapsed [0:13:04.906215] batch: 160  d_loss: 0.169172  g_loss: 5.471489\n",
      "Elapsed [0:13:23.095289] batch: 200  d_loss: 0.167154  g_loss: 7.767927\n",
      "Elapsed [0:13:41.743950] batch: 240  d_loss: 0.195062  g_loss: 5.233889\n",
      "Elapsed [0:13:59.526639] batch: 280  d_loss: 0.170205  g_loss: 4.503551\n",
      "Elapsed [0:14:18.416923] batch: 320  d_loss: 0.162659  g_loss: 7.706709\n",
      "Elapsed [0:14:36.676099] batch: 360  d_loss: 0.165137  g_loss: 5.792151\n",
      "Time taken for epoch: 177.347 secs\n",
      "\n",
      "Epoch: 6\n",
      "Elapsed [0:15:07.454131] batch: 40  d_loss: 0.167056  g_loss: 4.649316\n",
      "Elapsed [0:15:26.584027] batch: 80  d_loss: 0.163859  g_loss: 6.037310\n",
      "Elapsed [0:15:45.016466] batch: 120  d_loss: 0.165032  g_loss: 5.806910\n",
      "Elapsed [0:16:03.070803] batch: 160  d_loss: 0.164062  g_loss: 5.859366\n",
      "Elapsed [0:16:21.712391] batch: 200  d_loss: 0.164489  g_loss: 5.135730\n",
      "Elapsed [0:16:40.357396] batch: 240  d_loss: 0.163627  g_loss: 6.322552\n",
      "Elapsed [0:16:58.854287] batch: 280  d_loss: 0.173451  g_loss: 4.216219\n",
      "Elapsed [0:17:17.062201] batch: 320  d_loss: 0.171348  g_loss: 4.343590\n",
      "Elapsed [0:17:34.899843] batch: 360  d_loss: 0.167514  g_loss: 4.547890\n",
      "Time taken for epoch: 177.507 secs\n",
      "\n",
      "Epoch: 7\n",
      "Elapsed [0:18:06.096923] batch: 40  d_loss: 0.164338  g_loss: 5.841311\n",
      "Elapsed [0:18:24.697816] batch: 80  d_loss: 0.182657  g_loss: 7.717895\n",
      "Elapsed [0:18:42.117434] batch: 120  d_loss: 0.169731  g_loss: 4.860500\n",
      "Elapsed [0:19:00.508479] batch: 160  d_loss: 0.165606  g_loss: 6.005964\n",
      "Elapsed [0:19:18.048625] batch: 200  d_loss: 0.162862  g_loss: 6.800279\n",
      "Elapsed [0:19:35.494543] batch: 240  d_loss: 0.164523  g_loss: 5.189097\n",
      "Elapsed [0:19:54.882408] batch: 280  d_loss: 0.166261  g_loss: 4.967426\n",
      "Elapsed [0:20:12.826679] batch: 320  d_loss: 0.164986  g_loss: 5.779824\n",
      "Elapsed [0:20:30.194274] batch: 360  d_loss: 0.164767  g_loss: 6.048296\n",
      "Time taken for epoch: 175.468 secs\n",
      "\n",
      "Epoch: 8\n",
      "Elapsed [0:21:00.761641] batch: 40  d_loss: 0.163648  g_loss: 6.751705\n",
      "Elapsed [0:21:18.739111] batch: 80  d_loss: 0.192582  g_loss: 4.739676\n",
      "Elapsed [0:21:36.719448] batch: 120  d_loss: 0.163252  g_loss: 6.363101\n",
      "Elapsed [0:21:56.047711] batch: 160  d_loss: 0.165175  g_loss: 5.460776\n",
      "Elapsed [0:22:14.008150] batch: 200  d_loss: 0.166226  g_loss: 5.460529\n",
      "Elapsed [0:22:32.087889] batch: 240  d_loss: 0.163346  g_loss: 6.397981\n",
      "Elapsed [0:22:49.595378] batch: 280  d_loss: 0.164963  g_loss: 5.189752\n",
      "Elapsed [0:23:07.060210] batch: 320  d_loss: 0.163346  g_loss: 6.838040\n",
      "Elapsed [0:23:25.916958] batch: 360  d_loss: 0.168002  g_loss: 4.941705\n",
      "Time taken for epoch: 175.767 secs\n",
      "\n",
      "Epoch: 9\n",
      "Elapsed [0:23:56.178187] batch: 40  d_loss: 0.165558  g_loss: 6.099908\n",
      "Elapsed [0:24:14.662249] batch: 80  d_loss: 0.166729  g_loss: 5.154871\n",
      "Elapsed [0:24:32.860768] batch: 120  d_loss: 0.165825  g_loss: 4.973293\n",
      "Elapsed [0:24:50.423439] batch: 160  d_loss: 0.171417  g_loss: 7.150782\n",
      "Elapsed [0:25:09.200917] batch: 200  d_loss: 0.172555  g_loss: 6.511649\n",
      "Elapsed [0:25:28.113762] batch: 240  d_loss: 0.163121  g_loss: 6.174479\n",
      "Elapsed [0:25:46.057516] batch: 280  d_loss: 0.179910  g_loss: 5.678958\n",
      "Elapsed [0:26:03.891598] batch: 320  d_loss: 0.162915  g_loss: 6.631051\n",
      "Elapsed [0:26:21.501320] batch: 360  d_loss: 0.163109  g_loss: 6.756087\n",
      "Time taken for epoch: 175.298 secs\n",
      "\n",
      "Epoch: 10\n",
      "Elapsed [0:26:51.513766] batch: 40  d_loss: 0.164801  g_loss: 7.317508\n",
      "Elapsed [0:27:10.464697] batch: 80  d_loss: 0.164141  g_loss: 7.234953\n",
      "Elapsed [0:27:28.475549] batch: 120  d_loss: 0.186794  g_loss: 4.810673\n",
      "Elapsed [0:27:46.484165] batch: 160  d_loss: 0.163508  g_loss: 5.735024\n",
      "Elapsed [0:28:05.031645] batch: 200  d_loss: 0.163142  g_loss: 6.172172\n",
      "Elapsed [0:28:22.693325] batch: 240  d_loss: 0.164460  g_loss: 6.008179\n",
      "Elapsed [0:28:41.137881] batch: 280  d_loss: 0.164691  g_loss: 5.085684\n",
      "Elapsed [0:28:59.940815] batch: 320  d_loss: 0.164831  g_loss: 5.338156\n",
      "Elapsed [0:29:18.613650] batch: 360  d_loss: 0.304323  g_loss: 2.179674\n",
      "Time taken for epoch: 177.466 secs\n",
      "\n",
      "Epoch: 11\n",
      "Elapsed [0:29:57.911880] batch: 40  d_loss: 0.166336  g_loss: 6.585526\n",
      "Elapsed [0:30:18.710500] batch: 80  d_loss: 0.165085  g_loss: 6.809866\n",
      "Elapsed [0:30:36.647855] batch: 120  d_loss: 0.163389  g_loss: 5.939956\n",
      "Elapsed [0:30:54.567737] batch: 160  d_loss: 0.164003  g_loss: 7.186275\n",
      "Elapsed [0:31:12.310773] batch: 200  d_loss: 0.168870  g_loss: 5.077740\n",
      "Elapsed [0:31:30.568280] batch: 240  d_loss: 0.164930  g_loss: 6.029699\n",
      "Elapsed [0:31:48.712271] batch: 280  d_loss: 0.170824  g_loss: 4.555833\n",
      "Elapsed [0:32:08.299832] batch: 320  d_loss: 0.172072  g_loss: 4.353454\n",
      "Elapsed [0:32:26.647424] batch: 360  d_loss: 0.162918  g_loss: 6.511614\n",
      "Time taken for epoch: 183.678 secs\n",
      "\n",
      "Epoch: 12\n",
      "Elapsed [0:32:56.411249] batch: 40  d_loss: 0.179981  g_loss: 7.202881\n",
      "Elapsed [0:33:15.487855] batch: 80  d_loss: 0.166020  g_loss: 6.519454\n",
      "Elapsed [0:33:33.172205] batch: 120  d_loss: 0.186188  g_loss: 5.677246\n",
      "Elapsed [0:33:50.972517] batch: 160  d_loss: 0.163114  g_loss: 6.787678\n",
      "Elapsed [0:34:09.136354] batch: 200  d_loss: 0.162641  g_loss: 8.657620\n",
      "Elapsed [0:34:27.616501] batch: 240  d_loss: 0.183151  g_loss: 3.745999\n",
      "Elapsed [0:34:45.836195] batch: 280  d_loss: 0.163112  g_loss: 6.312046\n",
      "Elapsed [0:35:03.727262] batch: 320  d_loss: 0.165422  g_loss: 5.352968\n",
      "Elapsed [0:35:22.392621] batch: 360  d_loss: 0.168361  g_loss: 5.035373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for epoch: 176.345 secs\n",
      "\n",
      "Epoch: 13\n",
      "Elapsed [0:35:53.715354] batch: 40  d_loss: 0.162797  g_loss: 7.676990\n",
      "Elapsed [0:36:11.972507] batch: 80  d_loss: 0.165485  g_loss: 7.296337\n",
      "Elapsed [0:36:30.308765] batch: 120  d_loss: 0.183822  g_loss: 4.741402\n",
      "Elapsed [0:36:48.264463] batch: 160  d_loss: 0.163877  g_loss: 5.861598\n",
      "Elapsed [0:37:07.019266] batch: 200  d_loss: 0.182817  g_loss: 4.316624\n",
      "Elapsed [0:37:24.731441] batch: 240  d_loss: 0.167585  g_loss: 6.419403\n",
      "Elapsed [0:37:42.361466] batch: 280  d_loss: 0.169408  g_loss: 6.461421\n",
      "Elapsed [0:38:00.950055] batch: 320  d_loss: 0.171612  g_loss: 7.024603\n",
      "Elapsed [0:38:18.742972] batch: 360  d_loss: 0.171033  g_loss: 8.216120\n",
      "Time taken for epoch: 176.539 secs\n",
      "\n",
      "Epoch: 14\n",
      "Elapsed [0:38:49.615621] batch: 40  d_loss: 0.166928  g_loss: 5.463449\n",
      "Elapsed [0:39:08.481566] batch: 80  d_loss: 0.163448  g_loss: 6.128669\n",
      "Elapsed [0:39:26.173232] batch: 120  d_loss: 0.164568  g_loss: 6.133421\n",
      "Elapsed [0:39:44.507865] batch: 160  d_loss: 0.164327  g_loss: 5.698095\n",
      "Elapsed [0:40:03.904559] batch: 200  d_loss: 0.162662  g_loss: 8.285822\n",
      "Elapsed [0:40:22.134301] batch: 240  d_loss: 0.168879  g_loss: 4.958605\n",
      "Elapsed [0:40:40.690657] batch: 280  d_loss: 0.167110  g_loss: 5.129251\n",
      "Elapsed [0:40:58.440562] batch: 320  d_loss: 0.162718  g_loss: 7.969021\n",
      "Elapsed [0:41:16.179459] batch: 360  d_loss: 0.165640  g_loss: 6.212551\n",
      "Time taken for epoch: 176.709 secs\n",
      "\n",
      "Epoch: 15\n",
      "Elapsed [0:41:45.747647] batch: 40  d_loss: 0.188068  g_loss: 4.886724\n",
      "Elapsed [0:42:03.796000] batch: 80  d_loss: 0.237440  g_loss: 5.634029\n",
      "Elapsed [0:42:22.909500] batch: 120  d_loss: 0.165603  g_loss: 6.789427\n",
      "Elapsed [0:42:41.249509] batch: 160  d_loss: 0.177510  g_loss: 3.954086\n",
      "Elapsed [0:42:58.856445] batch: 200  d_loss: 0.166414  g_loss: 4.625712\n",
      "Elapsed [0:43:17.234391] batch: 240  d_loss: 0.167862  g_loss: 4.405535\n",
      "Elapsed [0:43:35.376162] batch: 280  d_loss: 0.167483  g_loss: 6.088817\n",
      "Elapsed [0:43:53.472563] batch: 320  d_loss: 0.163713  g_loss: 9.070499\n",
      "Elapsed [0:44:11.415697] batch: 360  d_loss: 0.173577  g_loss: 5.587356\n",
      "Time taken for epoch: 176.703 secs\n",
      "\n",
      "Epoch: 16\n",
      "Elapsed [0:44:42.689405] batch: 40  d_loss: 0.167336  g_loss: 7.181578\n",
      "Elapsed [0:45:01.314205] batch: 80  d_loss: 0.162697  g_loss: 7.330305\n",
      "Elapsed [0:45:20.615819] batch: 120  d_loss: 0.193604  g_loss: 4.238863\n",
      "Elapsed [0:45:39.130166] batch: 160  d_loss: 0.172747  g_loss: 3.986167\n",
      "Elapsed [0:45:56.871977] batch: 200  d_loss: 0.171832  g_loss: 7.139458\n",
      "Elapsed [0:46:14.791949] batch: 240  d_loss: 0.173208  g_loss: 6.620476\n",
      "Elapsed [0:46:32.876463] batch: 280  d_loss: 0.174194  g_loss: 4.287623\n",
      "Elapsed [0:46:50.717484] batch: 320  d_loss: 0.167462  g_loss: 6.674045\n",
      "Elapsed [0:47:08.819400] batch: 360  d_loss: 0.165488  g_loss: 5.479919\n",
      "Time taken for epoch: 176.174 secs\n",
      "\n",
      "Epoch: 17\n",
      "Elapsed [0:47:39.693204] batch: 40  d_loss: 0.175556  g_loss: 5.081592\n",
      "Elapsed [0:47:57.969903] batch: 80  d_loss: 0.162797  g_loss: 6.841260\n",
      "Elapsed [0:48:17.551764] batch: 120  d_loss: 0.163523  g_loss: 7.563496\n",
      "Elapsed [0:48:35.301173] batch: 160  d_loss: 0.165841  g_loss: 4.675864\n",
      "Elapsed [0:48:52.778535] batch: 200  d_loss: 0.170852  g_loss: 5.122538\n",
      "Elapsed [0:49:11.066871] batch: 240  d_loss: 0.164297  g_loss: 6.264866\n",
      "Elapsed [0:49:29.273819] batch: 280  d_loss: 0.171198  g_loss: 4.408588\n",
      "Elapsed [0:49:47.056060] batch: 320  d_loss: 0.174174  g_loss: 5.402604\n",
      "Elapsed [0:50:04.796253] batch: 360  d_loss: 0.164285  g_loss: 7.048047\n",
      "Time taken for epoch: 175.940 secs\n",
      "\n",
      "Epoch: 18\n",
      "Elapsed [0:50:34.997884] batch: 40  d_loss: 0.168275  g_loss: 6.598999\n",
      "Elapsed [0:50:53.128129] batch: 80  d_loss: 0.162703  g_loss: 8.336288\n",
      "Elapsed [0:51:11.262560] batch: 120  d_loss: 0.171395  g_loss: 5.865225\n",
      "Elapsed [0:51:28.989466] batch: 160  d_loss: 0.164254  g_loss: 5.213499\n",
      "Elapsed [0:51:47.060905] batch: 200  d_loss: 0.164017  g_loss: 5.338166\n",
      "Elapsed [0:52:05.242949] batch: 240  d_loss: 0.164257  g_loss: 5.906218\n",
      "Elapsed [0:52:22.660299] batch: 280  d_loss: 0.173660  g_loss: 6.062654\n",
      "Elapsed [0:52:41.290334] batch: 320  d_loss: 0.170822  g_loss: 3.970367\n",
      "Elapsed [0:52:59.723845] batch: 360  d_loss: 0.176472  g_loss: 5.689919\n",
      "Time taken for epoch: 175.257 secs\n",
      "\n",
      "Epoch: 19\n",
      "Elapsed [0:53:30.899208] batch: 40  d_loss: 0.182860  g_loss: 5.722804\n",
      "Elapsed [0:53:48.768985] batch: 80  d_loss: 0.164350  g_loss: 5.678205\n",
      "Elapsed [0:54:07.633111] batch: 120  d_loss: 0.175272  g_loss: 4.311044\n",
      "Elapsed [0:54:25.223330] batch: 160  d_loss: 0.166438  g_loss: 4.829378\n",
      "Elapsed [0:54:42.730911] batch: 200  d_loss: 0.164791  g_loss: 7.611080\n",
      "Elapsed [0:55:00.308150] batch: 240  d_loss: 0.213586  g_loss: 6.547029\n",
      "Elapsed [0:55:18.464567] batch: 280  d_loss: 0.222054  g_loss: 7.110495\n",
      "Elapsed [0:55:37.635025] batch: 320  d_loss: 0.191190  g_loss: 4.567685\n",
      "Elapsed [0:55:56.261780] batch: 360  d_loss: 0.166883  g_loss: 4.735235\n",
      "Time taken for epoch: 175.732 secs\n",
      "\n",
      "Epoch: 20\n",
      "Elapsed [0:56:26.657149] batch: 40  d_loss: 0.169266  g_loss: 5.641121\n",
      "Elapsed [0:56:45.520423] batch: 80  d_loss: 0.165667  g_loss: 5.394961\n",
      "Elapsed [0:57:03.059230] batch: 120  d_loss: 0.163419  g_loss: 5.990108\n",
      "Elapsed [0:57:20.819232] batch: 160  d_loss: 0.170485  g_loss: 4.475366\n",
      "Elapsed [0:57:38.651980] batch: 200  d_loss: 0.163020  g_loss: 6.285822\n",
      "Elapsed [0:57:56.736909] batch: 240  d_loss: 0.164126  g_loss: 5.305439\n",
      "Elapsed [0:58:15.476518] batch: 280  d_loss: 0.172710  g_loss: 6.179456\n",
      "Elapsed [0:58:33.425189] batch: 320  d_loss: 0.164359  g_loss: 5.809543\n",
      "Elapsed [0:58:51.897077] batch: 360  d_loss: 0.189421  g_loss: 4.353807\n",
      "Time taken for epoch: 176.535 secs\n",
      "\n",
      "Epoch: 21\n",
      "Elapsed [0:59:23.983098] batch: 40  d_loss: 0.163987  g_loss: 7.913638\n",
      "Elapsed [0:59:42.729231] batch: 80  d_loss: 0.169075  g_loss: 4.751579\n",
      "Elapsed [1:00:00.420425] batch: 120  d_loss: 0.164251  g_loss: 5.291897\n",
      "Elapsed [1:00:18.685214] batch: 160  d_loss: 0.169266  g_loss: 4.497878\n",
      "Elapsed [1:00:36.760226] batch: 200  d_loss: 0.168279  g_loss: 4.469071\n",
      "Elapsed [1:00:54.839768] batch: 240  d_loss: 0.193799  g_loss: 3.712952\n",
      "Elapsed [1:01:13.470017] batch: 280  d_loss: 0.163825  g_loss: 7.537769\n",
      "Elapsed [1:01:31.921667] batch: 320  d_loss: 0.185318  g_loss: 8.041346\n",
      "Elapsed [1:01:50.334251] batch: 360  d_loss: 0.176689  g_loss: 6.369240\n",
      "Time taken for epoch: 176.085 secs\n",
      "\n",
      "Epoch: 22\n",
      "Elapsed [1:02:20.163415] batch: 40  d_loss: 0.167665  g_loss: 9.017583\n",
      "Elapsed [1:02:38.187004] batch: 80  d_loss: 0.173078  g_loss: 5.585227\n",
      "Elapsed [1:02:56.511873] batch: 120  d_loss: 0.164358  g_loss: 6.797683\n",
      "Elapsed [1:03:15.872333] batch: 160  d_loss: 0.165411  g_loss: 6.235122\n",
      "Elapsed [1:03:33.776949] batch: 200  d_loss: 0.165002  g_loss: 5.483323\n",
      "Elapsed [1:03:52.328183] batch: 240  d_loss: 0.167236  g_loss: 4.435890\n",
      "Elapsed [1:04:09.972862] batch: 280  d_loss: 0.172241  g_loss: 6.925673\n",
      "Elapsed [1:04:27.759240] batch: 320  d_loss: 0.167205  g_loss: 6.796394\n",
      "Elapsed [1:04:45.583597] batch: 360  d_loss: 0.169211  g_loss: 7.252655\n",
      "Time taken for epoch: 175.522 secs\n",
      "\n",
      "Epoch: 23\n",
      "Elapsed [1:05:15.421536] batch: 40  d_loss: 0.185987  g_loss: 4.063942\n",
      "Elapsed [1:05:33.486091] batch: 80  d_loss: 0.165007  g_loss: 5.400611\n",
      "Elapsed [1:05:53.078530] batch: 120  d_loss: 0.196792  g_loss: 4.198563\n",
      "Elapsed [1:06:10.874681] batch: 160  d_loss: 0.188384  g_loss: 4.199878\n",
      "Elapsed [1:06:29.378897] batch: 200  d_loss: 0.191332  g_loss: 4.352865\n",
      "Elapsed [1:06:47.695525] batch: 240  d_loss: 0.171792  g_loss: 4.714993\n",
      "Elapsed [1:07:05.322000] batch: 280  d_loss: 0.164586  g_loss: 6.208537\n",
      "Elapsed [1:07:23.264540] batch: 320  d_loss: 0.188221  g_loss: 5.260276\n",
      "Elapsed [1:07:41.922391] batch: 360  d_loss: 0.169269  g_loss: 7.275345\n",
      "Time taken for epoch: 176.050 secs\n",
      "\n",
      "Epoch: 24\n",
      "Elapsed [1:08:12.720516] batch: 40  d_loss: 0.166209  g_loss: 4.725941\n",
      "Elapsed [1:08:30.411803] batch: 80  d_loss: 0.183908  g_loss: 3.665993\n",
      "Elapsed [1:08:48.362457] batch: 120  d_loss: 0.200764  g_loss: 3.605232\n",
      "Elapsed [1:09:06.540145] batch: 160  d_loss: 0.165126  g_loss: 8.342930\n",
      "Elapsed [1:09:24.593084] batch: 200  d_loss: 0.163634  g_loss: 7.018292\n",
      "Elapsed [1:09:42.522622] batch: 240  d_loss: 0.167518  g_loss: 4.438043\n",
      "Elapsed [1:10:00.957407] batch: 280  d_loss: 0.163408  g_loss: 5.752747\n",
      "Elapsed [1:10:19.399290] batch: 320  d_loss: 0.167038  g_loss: 4.386874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed [1:10:37.378432] batch: 360  d_loss: 0.165129  g_loss: 6.688696\n",
      "Time taken for epoch: 175.399 secs\n",
      "\n",
      "Epoch: 25\n",
      "Elapsed [1:11:07.048115] batch: 40  d_loss: 0.162712  g_loss: 7.631296\n",
      "Elapsed [1:11:25.442029] batch: 80  d_loss: 0.175850  g_loss: 3.868346\n",
      "Elapsed [1:11:42.798753] batch: 120  d_loss: 0.165451  g_loss: 5.828510\n",
      "Elapsed [1:12:01.033247] batch: 160  d_loss: 0.177265  g_loss: 3.640032\n",
      "Elapsed [1:12:19.298242] batch: 200  d_loss: 0.169161  g_loss: 5.257630\n",
      "Elapsed [1:12:38.065598] batch: 240  d_loss: 0.165456  g_loss: 4.858663\n",
      "Elapsed [1:12:56.222813] batch: 280  d_loss: 0.163527  g_loss: 8.455005\n",
      "Elapsed [1:13:14.410621] batch: 320  d_loss: 0.179534  g_loss: 4.260782\n",
      "Elapsed [1:13:32.855277] batch: 360  d_loss: 0.169455  g_loss: 5.770987\n",
      "Time taken for epoch: 175.945 secs\n",
      "\n",
      "Epoch: 26\n",
      "Elapsed [1:14:03.370144] batch: 40  d_loss: 0.196267  g_loss: 5.055945\n",
      "Elapsed [1:14:21.688664] batch: 80  d_loss: 0.168362  g_loss: 4.554281\n",
      "Elapsed [1:14:40.631537] batch: 120  d_loss: 0.162855  g_loss: 6.662709\n",
      "Elapsed [1:14:58.406430] batch: 160  d_loss: 0.165700  g_loss: 8.684934\n",
      "Elapsed [1:15:16.691788] batch: 200  d_loss: 0.169259  g_loss: 6.918425\n",
      "Elapsed [1:15:34.389917] batch: 240  d_loss: 0.168321  g_loss: 4.535323\n",
      "Elapsed [1:15:51.981479] batch: 280  d_loss: 0.166456  g_loss: 4.541781\n",
      "Elapsed [1:16:10.013499] batch: 320  d_loss: 0.167333  g_loss: 8.330884\n",
      "Elapsed [1:16:28.982808] batch: 360  d_loss: 0.166053  g_loss: 5.095255\n",
      "Time taken for epoch: 175.756 secs\n",
      "\n",
      "Epoch: 27\n",
      "Elapsed [1:16:58.853896] batch: 40  d_loss: 0.170215  g_loss: 4.790081\n",
      "Elapsed [1:17:17.291872] batch: 80  d_loss: 0.166874  g_loss: 5.450669\n",
      "Elapsed [1:17:35.297765] batch: 120  d_loss: 0.170850  g_loss: 4.235231\n",
      "Elapsed [1:17:53.454741] batch: 160  d_loss: 0.164262  g_loss: 6.855911\n",
      "Elapsed [1:18:10.985805] batch: 200  d_loss: 0.168187  g_loss: 4.466412\n",
      "Elapsed [1:18:28.765368] batch: 240  d_loss: 0.166242  g_loss: 6.098047\n",
      "Elapsed [1:18:47.278659] batch: 280  d_loss: 0.163587  g_loss: 6.213566\n",
      "Elapsed [1:19:06.496046] batch: 320  d_loss: 0.208232  g_loss: 3.782138\n",
      "Elapsed [1:19:24.234096] batch: 360  d_loss: 0.171258  g_loss: 4.335401\n",
      "Time taken for epoch: 175.665 secs\n",
      "\n",
      "Epoch: 28\n",
      "Elapsed [1:19:55.698023] batch: 40  d_loss: 0.173703  g_loss: 3.788604\n",
      "Elapsed [1:20:14.287723] batch: 80  d_loss: 0.188703  g_loss: 3.718785\n",
      "Elapsed [1:20:31.685025] batch: 120  d_loss: 0.175134  g_loss: 4.582216\n",
      "Elapsed [1:20:49.654388] batch: 160  d_loss: 0.177838  g_loss: 4.340311\n",
      "Elapsed [1:21:07.082955] batch: 200  d_loss: 0.163135  g_loss: 6.090926\n",
      "Elapsed [1:21:25.973904] batch: 240  d_loss: 0.164216  g_loss: 5.343217\n",
      "Elapsed [1:21:44.031424] batch: 280  d_loss: 0.164801  g_loss: 5.907297\n",
      "Elapsed [1:22:02.733991] batch: 320  d_loss: 0.164133  g_loss: 5.766262\n",
      "Elapsed [1:22:21.367004] batch: 360  d_loss: 0.174402  g_loss: 4.733929\n",
      "Time taken for epoch: 179.321 secs\n",
      "\n",
      "Epoch: 29\n",
      "Elapsed [1:22:54.339281] batch: 40  d_loss: 0.168934  g_loss: 4.178087\n",
      "Elapsed [1:23:13.008802] batch: 80  d_loss: 0.168270  g_loss: 4.295957\n",
      "Elapsed [1:23:31.201381] batch: 120  d_loss: 0.168602  g_loss: 4.759623\n",
      "Elapsed [1:23:49.503770] batch: 160  d_loss: 0.167038  g_loss: 5.982058\n",
      "Elapsed [1:24:07.666775] batch: 200  d_loss: 0.164831  g_loss: 5.384372\n",
      "Elapsed [1:24:27.614364] batch: 240  d_loss: 0.176200  g_loss: 4.074886\n",
      "Elapsed [1:24:46.154955] batch: 280  d_loss: 0.185187  g_loss: 4.009390\n",
      "Elapsed [1:25:04.842598] batch: 320  d_loss: 0.166129  g_loss: 4.657468\n",
      "Elapsed [1:25:22.515610] batch: 360  d_loss: 0.165779  g_loss: 4.757108\n",
      "Time taken for epoch: 178.770 secs\n",
      "\n",
      "Epoch: 30\n",
      "Elapsed [1:25:53.060057] batch: 40  d_loss: 0.170697  g_loss: 4.460738\n",
      "Elapsed [1:26:12.402510] batch: 80  d_loss: 0.196002  g_loss: 3.575048\n",
      "Elapsed [1:26:31.090215] batch: 120  d_loss: 0.167411  g_loss: 5.760145\n",
      "Elapsed [1:26:49.673150] batch: 160  d_loss: 0.188536  g_loss: 4.412790\n",
      "Elapsed [1:27:07.625309] batch: 200  d_loss: 0.178161  g_loss: 4.130360\n",
      "Elapsed [1:27:26.225445] batch: 240  d_loss: 0.162937  g_loss: 7.875074\n",
      "Elapsed [1:27:45.255218] batch: 280  d_loss: 0.167266  g_loss: 6.659027\n",
      "Elapsed [1:28:03.904752] batch: 320  d_loss: 0.190430  g_loss: 4.918203\n",
      "Elapsed [1:28:23.766235] batch: 360  d_loss: 0.171333  g_loss: 4.859781\n",
      "Time taken for epoch: 182.300 secs\n",
      "\n",
      "Epoch: 31\n",
      "Elapsed [1:28:56.896742] batch: 40  d_loss: 0.166193  g_loss: 6.294923\n",
      "Elapsed [1:29:15.807525] batch: 80  d_loss: 0.171498  g_loss: 6.063251\n",
      "Elapsed [1:29:35.268040] batch: 120  d_loss: 0.173118  g_loss: 3.740431\n",
      "Elapsed [1:29:55.204000] batch: 160  d_loss: 0.179095  g_loss: 5.708148\n",
      "Elapsed [1:30:15.185100] batch: 200  d_loss: 0.177373  g_loss: 3.618049\n",
      "Elapsed [1:30:34.600895] batch: 240  d_loss: 0.168268  g_loss: 4.545818\n",
      "Elapsed [1:30:53.815180] batch: 280  d_loss: 0.164958  g_loss: 6.554875\n",
      "Elapsed [1:31:14.337218] batch: 320  d_loss: 0.167029  g_loss: 5.024401\n",
      "Elapsed [1:31:37.090752] batch: 360  d_loss: 0.174670  g_loss: 4.250923\n",
      "Time taken for epoch: 191.291 secs\n",
      "\n",
      "Epoch: 32\n",
      "Elapsed [1:32:09.663059] batch: 40  d_loss: 0.164449  g_loss: 5.317655\n",
      "Elapsed [1:32:28.788265] batch: 80  d_loss: 0.204707  g_loss: 2.772977\n",
      "Elapsed [1:32:49.056875] batch: 120  d_loss: 0.167075  g_loss: 4.974735\n",
      "Elapsed [1:33:08.572330] batch: 160  d_loss: 0.164841  g_loss: 4.927503\n",
      "Elapsed [1:33:29.877834] batch: 200  d_loss: 0.218597  g_loss: 3.710994\n",
      "Elapsed [1:33:49.552710] batch: 240  d_loss: 0.171926  g_loss: 5.232727\n",
      "Elapsed [1:34:09.970734] batch: 280  d_loss: 0.163349  g_loss: 6.206265\n",
      "Elapsed [1:34:32.944146] batch: 320  d_loss: 0.174797  g_loss: 3.809143\n",
      "Elapsed [1:34:51.959768] batch: 360  d_loss: 0.174358  g_loss: 4.458123\n",
      "Time taken for epoch: 194.843 secs\n",
      "\n",
      "Epoch: 33\n",
      "Elapsed [1:35:22.869425] batch: 40  d_loss: 0.162709  g_loss: 9.097795\n",
      "Elapsed [1:35:41.224282] batch: 80  d_loss: 0.163425  g_loss: 6.665984\n",
      "Elapsed [1:35:59.266741] batch: 120  d_loss: 0.191762  g_loss: 4.402493\n",
      "Elapsed [1:36:18.226003] batch: 160  d_loss: 0.163062  g_loss: 7.655115\n",
      "Elapsed [1:36:36.944920] batch: 200  d_loss: 0.169872  g_loss: 7.392851\n",
      "Elapsed [1:36:56.240373] batch: 240  d_loss: 0.167997  g_loss: 6.705420\n",
      "Elapsed [1:37:16.463308] batch: 280  d_loss: 0.242271  g_loss: 5.071790\n",
      "Elapsed [1:37:35.277460] batch: 320  d_loss: 0.175704  g_loss: 5.384744\n",
      "Elapsed [1:37:54.669455] batch: 360  d_loss: 0.163144  g_loss: 6.967735\n",
      "Time taken for epoch: 182.947 secs\n",
      "\n",
      "Epoch: 34\n",
      "Elapsed [1:38:26.775734] batch: 40  d_loss: 0.168747  g_loss: 4.575810\n",
      "Elapsed [1:38:45.814996] batch: 80  d_loss: 0.163737  g_loss: 5.853575\n",
      "Elapsed [1:39:04.942886] batch: 120  d_loss: 0.176840  g_loss: 6.580750\n",
      "Elapsed [1:39:23.823743] batch: 160  d_loss: 0.172325  g_loss: 4.680456\n",
      "Elapsed [1:39:43.692708] batch: 200  d_loss: 0.166463  g_loss: 5.049743\n",
      "Elapsed [1:40:03.239200] batch: 240  d_loss: 0.162830  g_loss: 7.454867\n",
      "Elapsed [1:40:22.003573] batch: 280  d_loss: 0.173389  g_loss: 4.385716\n",
      "Elapsed [1:40:41.374946] batch: 320  d_loss: 0.173276  g_loss: 4.056501\n",
      "Elapsed [1:41:01.166054] batch: 360  d_loss: 0.166945  g_loss: 4.650274\n",
      "Time taken for epoch: 186.569 secs\n",
      "\n",
      "Epoch: 35\n",
      "Elapsed [1:41:33.852554] batch: 40  d_loss: 0.163171  g_loss: 7.429706\n",
      "Elapsed [1:41:52.790010] batch: 80  d_loss: 0.163675  g_loss: 5.693140\n",
      "Elapsed [1:42:12.613129] batch: 120  d_loss: 0.170969  g_loss: 4.939492\n",
      "Elapsed [1:42:31.454110] batch: 160  d_loss: 0.167284  g_loss: 4.436769\n",
      "Elapsed [1:42:51.174657] batch: 200  d_loss: 0.193434  g_loss: 3.852869\n",
      "Elapsed [1:43:10.599059] batch: 240  d_loss: 0.186644  g_loss: 4.203323\n",
      "Elapsed [1:43:30.022614] batch: 280  d_loss: 0.164683  g_loss: 6.639415\n",
      "Elapsed [1:43:49.830966] batch: 320  d_loss: 0.229867  g_loss: 4.089378\n",
      "Elapsed [1:44:08.229938] batch: 360  d_loss: 0.165861  g_loss: 4.644054\n",
      "Time taken for epoch: 186.348 secs\n",
      "\n",
      "Epoch: 36\n",
      "Elapsed [1:44:39.460396] batch: 40  d_loss: 0.179036  g_loss: 3.642322\n",
      "Elapsed [1:44:57.668679] batch: 80  d_loss: 0.164004  g_loss: 5.375109\n",
      "Elapsed [1:45:15.590208] batch: 120  d_loss: 0.164359  g_loss: 5.408742\n",
      "Elapsed [1:45:35.101080] batch: 160  d_loss: 0.163659  g_loss: 5.902499\n",
      "Elapsed [1:45:54.349679] batch: 200  d_loss: 0.184429  g_loss: 3.643492\n",
      "Elapsed [1:46:13.094687] batch: 240  d_loss: 0.227606  g_loss: 2.560042\n",
      "Elapsed [1:46:33.144086] batch: 280  d_loss: 0.177633  g_loss: 4.584169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed [1:46:51.551844] batch: 320  d_loss: 0.169373  g_loss: 5.090394\n",
      "Elapsed [1:47:10.487081] batch: 360  d_loss: 0.162780  g_loss: 6.912550\n",
      "Time taken for epoch: 183.218 secs\n",
      "\n",
      "Epoch: 37\n",
      "Elapsed [1:47:43.524505] batch: 40  d_loss: 0.178771  g_loss: 4.127937\n",
      "Elapsed [1:48:01.716327] batch: 80  d_loss: 0.172513  g_loss: 5.249418\n",
      "Elapsed [1:48:21.025154] batch: 120  d_loss: 0.165748  g_loss: 4.832312\n",
      "Elapsed [1:48:39.452142] batch: 160  d_loss: 0.208927  g_loss: 3.696122\n",
      "Elapsed [1:48:57.542092] batch: 200  d_loss: 0.166981  g_loss: 4.601999\n",
      "Elapsed [1:49:16.534099] batch: 240  d_loss: 0.164717  g_loss: 5.037337\n",
      "Elapsed [1:49:34.925991] batch: 280  d_loss: 0.163720  g_loss: 6.656817\n",
      "Elapsed [1:49:52.533510] batch: 320  d_loss: 0.236678  g_loss: 3.729093\n",
      "Elapsed [1:50:10.236388] batch: 360  d_loss: 0.165465  g_loss: 4.876777\n",
      "Time taken for epoch: 178.242 secs\n",
      "\n",
      "Epoch: 38\n",
      "Elapsed [1:50:40.497849] batch: 40  d_loss: 0.167457  g_loss: 4.745253\n",
      "Elapsed [1:50:58.552006] batch: 80  d_loss: 0.181993  g_loss: 4.320994\n",
      "Elapsed [1:51:16.125206] batch: 120  d_loss: 0.163314  g_loss: 6.153024\n",
      "Elapsed [1:51:34.673836] batch: 160  d_loss: 0.231042  g_loss: 2.912687\n",
      "Elapsed [1:51:53.813240] batch: 200  d_loss: 0.184137  g_loss: 7.362792\n",
      "Elapsed [1:52:11.639928] batch: 240  d_loss: 0.167083  g_loss: 5.585289\n",
      "Elapsed [1:52:29.272555] batch: 280  d_loss: 0.199691  g_loss: 4.882661\n",
      "Elapsed [1:52:48.280433] batch: 320  d_loss: 0.176212  g_loss: 3.928378\n",
      "Elapsed [1:53:06.356602] batch: 360  d_loss: 0.182650  g_loss: 3.560035\n",
      "Time taken for epoch: 176.299 secs\n",
      "\n",
      "Epoch: 39\n",
      "Elapsed [1:53:35.787600] batch: 40  d_loss: 0.174902  g_loss: 7.828815\n",
      "Elapsed [1:53:53.943179] batch: 80  d_loss: 0.163375  g_loss: 6.911061\n",
      "Elapsed [1:54:12.858278] batch: 120  d_loss: 0.164998  g_loss: 5.470540\n",
      "Elapsed [1:54:31.838800] batch: 160  d_loss: 0.200090  g_loss: 5.102031\n",
      "Elapsed [1:54:50.289456] batch: 200  d_loss: 0.177771  g_loss: 3.719666\n",
      "Elapsed [1:55:07.950063] batch: 240  d_loss: 0.173426  g_loss: 3.934663\n",
      "Elapsed [1:55:26.402081] batch: 280  d_loss: 0.242453  g_loss: 6.172243\n",
      "Elapsed [1:55:44.340035] batch: 320  d_loss: 0.164043  g_loss: 5.397226\n",
      "Elapsed [1:56:01.903802] batch: 360  d_loss: 0.163511  g_loss: 6.500331\n",
      "Time taken for epoch: 176.564 secs\n",
      "\n",
      "Epoch: 40\n",
      "Elapsed [1:56:32.809537] batch: 40  d_loss: 0.178864  g_loss: 5.009874\n",
      "Elapsed [1:56:51.374693] batch: 80  d_loss: 0.163474  g_loss: 5.883989\n",
      "Elapsed [1:57:08.848084] batch: 120  d_loss: 0.163167  g_loss: 6.371522\n",
      "Elapsed [1:57:27.427006] batch: 160  d_loss: 0.185173  g_loss: 4.431799\n",
      "Elapsed [1:57:46.683516] batch: 200  d_loss: 0.162928  g_loss: 7.945849\n",
      "Elapsed [1:58:04.835838] batch: 240  d_loss: 0.163426  g_loss: 5.837189\n",
      "Elapsed [1:58:22.874647] batch: 280  d_loss: 0.179764  g_loss: 4.183337\n",
      "Elapsed [1:58:41.303300] batch: 320  d_loss: 0.173479  g_loss: 4.138974\n",
      "Elapsed [1:58:59.204081] batch: 360  d_loss: 0.169374  g_loss: 4.661122\n",
      "Time taken for epoch: 176.218 secs\n",
      "\n",
      "Epoch: 41\n",
      "Elapsed [1:59:32.347938] batch: 40  d_loss: 0.178330  g_loss: 3.766734\n",
      "Elapsed [1:59:51.054916] batch: 80  d_loss: 0.164251  g_loss: 5.659369\n",
      "Elapsed [2:00:10.540776] batch: 120  d_loss: 0.196138  g_loss: 3.905913\n",
      "Elapsed [2:00:28.784787] batch: 160  d_loss: 0.163772  g_loss: 6.109179\n",
      "Elapsed [2:00:47.397649] batch: 200  d_loss: 0.171157  g_loss: 5.914329\n",
      "Elapsed [2:01:04.890317] batch: 240  d_loss: 0.163411  g_loss: 6.150819\n",
      "Elapsed [2:01:23.230805] batch: 280  d_loss: 0.529333  g_loss: 2.722758\n",
      "Elapsed [2:01:41.471406] batch: 320  d_loss: 0.195736  g_loss: 3.799366\n",
      "Elapsed [2:01:59.735640] batch: 360  d_loss: 0.164792  g_loss: 6.367818\n",
      "Time taken for epoch: 177.626 secs\n",
      "\n",
      "Epoch: 42\n",
      "Elapsed [2:02:30.037831] batch: 40  d_loss: 0.164208  g_loss: 6.128775\n",
      "Elapsed [2:02:48.772762] batch: 80  d_loss: 0.175148  g_loss: 6.252861\n",
      "Elapsed [2:03:06.987850] batch: 120  d_loss: 0.169820  g_loss: 4.545554\n",
      "Elapsed [2:03:25.185036] batch: 160  d_loss: 0.170068  g_loss: 4.379732\n",
      "Elapsed [2:03:42.724121] batch: 200  d_loss: 0.595895  g_loss: 6.133713\n",
      "Elapsed [2:04:01.044476] batch: 240  d_loss: 0.197108  g_loss: 3.729342\n",
      "Elapsed [2:04:19.732558] batch: 280  d_loss: 0.180644  g_loss: 3.516605\n",
      "Elapsed [2:04:37.049115] batch: 320  d_loss: 0.162729  g_loss: 7.143851\n",
      "Elapsed [2:04:55.639667] batch: 360  d_loss: 0.206641  g_loss: 3.073284\n",
      "Time taken for epoch: 176.329 secs\n",
      "\n",
      "Epoch: 43\n",
      "Elapsed [2:05:27.502903] batch: 40  d_loss: 0.177527  g_loss: 5.430295\n",
      "Elapsed [2:05:45.211808] batch: 80  d_loss: 0.168635  g_loss: 4.651330\n",
      "Elapsed [2:06:02.777264] batch: 120  d_loss: 0.170303  g_loss: 4.074546\n",
      "Elapsed [2:06:20.926251] batch: 160  d_loss: 0.168845  g_loss: 5.232939\n",
      "Elapsed [2:06:38.545612] batch: 200  d_loss: 0.168723  g_loss: 8.251483\n",
      "Elapsed [2:06:56.067944] batch: 240  d_loss: 0.176409  g_loss: 3.784193\n",
      "Elapsed [2:07:14.026533] batch: 280  d_loss: 0.172989  g_loss: 3.896511\n",
      "Elapsed [2:07:32.102914] batch: 320  d_loss: 0.164354  g_loss: 5.219980\n",
      "Elapsed [2:07:51.144651] batch: 360  d_loss: 0.166881  g_loss: 5.678890\n",
      "Time taken for epoch: 175.436 secs\n",
      "\n",
      "Epoch: 44\n",
      "Elapsed [2:08:22.805533] batch: 40  d_loss: 0.230130  g_loss: 3.930500\n",
      "Elapsed [2:08:40.824644] batch: 80  d_loss: 0.164655  g_loss: 5.093076\n",
      "Elapsed [2:08:59.012975] batch: 120  d_loss: 0.173287  g_loss: 4.395468\n",
      "Elapsed [2:09:17.194529] batch: 160  d_loss: 0.176095  g_loss: 3.600122\n",
      "Elapsed [2:09:35.373730] batch: 200  d_loss: 0.172605  g_loss: 6.288510\n",
      "Elapsed [2:09:53.040019] batch: 240  d_loss: 0.162639  g_loss: 8.032102\n",
      "Elapsed [2:10:11.085286] batch: 280  d_loss: 0.165407  g_loss: 4.850693\n",
      "Elapsed [2:10:28.555434] batch: 320  d_loss: 0.163967  g_loss: 5.393458\n",
      "Elapsed [2:10:46.300798] batch: 360  d_loss: 0.163556  g_loss: 5.904785\n",
      "Time taken for epoch: 175.454 secs\n",
      "\n",
      "Epoch: 45\n",
      "Elapsed [2:11:16.723688] batch: 40  d_loss: 0.169799  g_loss: 4.253240\n",
      "Elapsed [2:11:34.374574] batch: 80  d_loss: 0.186480  g_loss: 4.449699\n",
      "Elapsed [2:11:52.414229] batch: 120  d_loss: 0.203930  g_loss: 7.772469\n",
      "Elapsed [2:12:10.918527] batch: 160  d_loss: 0.177917  g_loss: 3.874801\n",
      "Elapsed [2:12:29.529567] batch: 200  d_loss: 0.166615  g_loss: 6.145007\n",
      "Elapsed [2:12:47.678964] batch: 240  d_loss: 0.165289  g_loss: 5.480508\n",
      "Elapsed [2:13:05.460280] batch: 280  d_loss: 0.167138  g_loss: 5.835512\n",
      "Elapsed [2:13:22.909314] batch: 320  d_loss: 0.163949  g_loss: 6.647574\n",
      "Elapsed [2:13:42.271127] batch: 360  d_loss: 0.190097  g_loss: 4.764192\n",
      "Time taken for epoch: 175.465 secs\n",
      "\n",
      "Epoch: 46\n",
      "Elapsed [2:14:12.353435] batch: 40  d_loss: 0.187783  g_loss: 3.075561\n",
      "Elapsed [2:14:30.514964] batch: 80  d_loss: 0.185431  g_loss: 3.311371\n",
      "Elapsed [2:14:48.125556] batch: 120  d_loss: 0.175337  g_loss: 4.395929\n",
      "Elapsed [2:15:05.919157] batch: 160  d_loss: 0.169322  g_loss: 4.852186\n",
      "Elapsed [2:15:24.921546] batch: 200  d_loss: 0.339433  g_loss: 2.791756\n",
      "Elapsed [2:15:42.772160] batch: 240  d_loss: 0.186817  g_loss: 5.436591\n",
      "Elapsed [2:16:01.868090] batch: 280  d_loss: 0.165988  g_loss: 5.387290\n",
      "Elapsed [2:16:19.905575] batch: 320  d_loss: 0.173296  g_loss: 4.002594\n",
      "Elapsed [2:16:37.985105] batch: 360  d_loss: 0.163837  g_loss: 5.697798\n",
      "Time taken for epoch: 176.121 secs\n",
      "\n",
      "Epoch: 47\n",
      "Elapsed [2:17:08.308196] batch: 40  d_loss: 0.165106  g_loss: 5.051805\n",
      "Elapsed [2:17:26.803942] batch: 80  d_loss: 0.178741  g_loss: 5.350185\n",
      "Elapsed [2:17:44.789028] batch: 120  d_loss: 0.163775  g_loss: 5.661459\n",
      "Elapsed [2:18:03.512633] batch: 160  d_loss: 0.169545  g_loss: 5.455799\n",
      "Elapsed [2:18:20.999728] batch: 200  d_loss: 0.167233  g_loss: 5.021337\n",
      "Elapsed [2:18:38.870759] batch: 240  d_loss: 0.172749  g_loss: 4.173294\n",
      "Elapsed [2:18:58.598896] batch: 280  d_loss: 0.165408  g_loss: 5.593566\n",
      "Elapsed [2:19:16.902827] batch: 320  d_loss: 0.178925  g_loss: 4.056015\n",
      "Elapsed [2:19:34.889390] batch: 360  d_loss: 0.248227  g_loss: 5.904623\n",
      "Time taken for epoch: 176.364 secs\n",
      "\n",
      "Epoch: 48\n",
      "Elapsed [2:20:05.263944] batch: 40  d_loss: 0.175525  g_loss: 3.971389\n",
      "Elapsed [2:20:24.362019] batch: 80  d_loss: 0.168429  g_loss: 6.881588\n",
      "Elapsed [2:20:42.436862] batch: 120  d_loss: 0.187459  g_loss: 3.592734\n",
      "Elapsed [2:21:00.091773] batch: 160  d_loss: 0.179231  g_loss: 3.738222\n",
      "Elapsed [2:21:18.837536] batch: 200  d_loss: 0.164710  g_loss: 5.741214\n",
      "Elapsed [2:21:36.683384] batch: 240  d_loss: 0.166293  g_loss: 6.627007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed [2:21:54.200478] batch: 280  d_loss: 0.179562  g_loss: 3.724975\n",
      "Elapsed [2:22:12.407834] batch: 320  d_loss: 0.167207  g_loss: 4.704003\n",
      "Elapsed [2:22:30.868299] batch: 360  d_loss: 0.165103  g_loss: 6.068410\n",
      "Time taken for epoch: 176.495 secs\n",
      "\n",
      "Epoch: 49\n",
      "Elapsed [2:23:01.205429] batch: 40  d_loss: 0.166463  g_loss: 5.356653\n",
      "Elapsed [2:23:19.839576] batch: 80  d_loss: 0.163506  g_loss: 8.344935\n",
      "Elapsed [2:23:38.044491] batch: 120  d_loss: 0.167701  g_loss: 4.907684\n",
      "Elapsed [2:23:55.424609] batch: 160  d_loss: 0.164004  g_loss: 5.528056\n",
      "Elapsed [2:24:13.257064] batch: 200  d_loss: 0.163340  g_loss: 6.137459\n",
      "Elapsed [2:24:31.663581] batch: 240  d_loss: 0.183387  g_loss: 6.500065\n",
      "Elapsed [2:24:50.156848] batch: 280  d_loss: 0.163546  g_loss: 5.653981\n",
      "Elapsed [2:25:08.839988] batch: 320  d_loss: 0.163641  g_loss: 5.962052\n",
      "Elapsed [2:25:26.264488] batch: 360  d_loss: 0.163171  g_loss: 6.231571\n",
      "Time taken for epoch: 175.879 secs\n",
      "\n",
      "Epoch: 50\n",
      "Elapsed [2:25:57.730338] batch: 40  d_loss: 0.170038  g_loss: 4.266946\n",
      "Elapsed [2:26:15.602306] batch: 80  d_loss: 0.166796  g_loss: 4.433179\n",
      "Elapsed [2:26:33.580000] batch: 120  d_loss: 0.164604  g_loss: 5.199568\n",
      "Elapsed [2:26:52.161556] batch: 160  d_loss: 0.205319  g_loss: 4.405935\n",
      "Elapsed [2:27:10.353041] batch: 200  d_loss: 0.164681  g_loss: 5.427891\n",
      "Elapsed [2:27:28.220672] batch: 240  d_loss: 0.164275  g_loss: 5.166485\n",
      "Elapsed [2:27:46.116142] batch: 280  d_loss: 0.167689  g_loss: 5.076491\n",
      "Elapsed [2:28:04.261647] batch: 320  d_loss: 0.166563  g_loss: 5.939862\n",
      "Elapsed [2:28:22.437944] batch: 360  d_loss: 0.174750  g_loss: 3.764182\n",
      "Time taken for epoch: 175.556 secs\n",
      "\n",
      "Epoch: 51\n",
      "Elapsed [2:29:00.275358] batch: 40  d_loss: 0.172323  g_loss: 4.503050\n",
      "Elapsed [2:29:19.379767] batch: 80  d_loss: 0.165677  g_loss: 4.818075\n",
      "Elapsed [2:29:37.353714] batch: 120  d_loss: 0.221345  g_loss: 2.708077\n",
      "Elapsed [2:29:55.631604] batch: 160  d_loss: 0.165686  g_loss: 4.920047\n",
      "Elapsed [2:30:13.628218] batch: 200  d_loss: 0.176371  g_loss: 5.973195\n",
      "Elapsed [2:30:31.055453] batch: 240  d_loss: 0.242218  g_loss: 3.107077\n",
      "Elapsed [2:30:49.421564] batch: 280  d_loss: 0.219267  g_loss: 4.020223\n",
      "Elapsed [2:31:07.231590] batch: 320  d_loss: 0.165977  g_loss: 6.111863\n",
      "Elapsed [2:31:25.028293] batch: 360  d_loss: 0.166857  g_loss: 6.810776\n",
      "Time taken for epoch: 176.211 secs\n",
      "\n",
      "Epoch: 52\n",
      "Elapsed [2:31:54.980013] batch: 40  d_loss: 0.165771  g_loss: 4.706119\n",
      "Elapsed [2:32:12.552832] batch: 80  d_loss: 0.328766  g_loss: 3.617297\n",
      "Elapsed [2:32:29.795062] batch: 120  d_loss: 0.175131  g_loss: 4.415864\n",
      "Elapsed [2:32:47.919272] batch: 160  d_loss: 0.164169  g_loss: 7.370543\n",
      "Elapsed [2:33:06.151399] batch: 200  d_loss: 0.165407  g_loss: 4.776614\n",
      "Elapsed [2:33:24.311931] batch: 240  d_loss: 0.239782  g_loss: 4.338617\n",
      "Elapsed [2:33:42.168497] batch: 280  d_loss: 0.163379  g_loss: 5.816691\n",
      "Elapsed [2:34:00.429310] batch: 320  d_loss: 0.165849  g_loss: 4.827881\n",
      "Elapsed [2:34:18.319767] batch: 360  d_loss: 0.167811  g_loss: 5.317451\n",
      "Time taken for epoch: 174.923 secs\n",
      "\n",
      "Epoch: 53\n",
      "Elapsed [2:34:50.462675] batch: 40  d_loss: 0.165587  g_loss: 5.882601\n",
      "Elapsed [2:35:09.341555] batch: 80  d_loss: 0.166047  g_loss: 5.648052\n",
      "Elapsed [2:35:27.095925] batch: 120  d_loss: 0.195252  g_loss: 3.963215\n",
      "Elapsed [2:35:45.799187] batch: 160  d_loss: 0.165778  g_loss: 5.069426\n",
      "Elapsed [2:36:03.365969] batch: 200  d_loss: 0.166302  g_loss: 5.179467\n",
      "Elapsed [2:36:21.369760] batch: 240  d_loss: 0.163196  g_loss: 6.518538\n",
      "Elapsed [2:36:39.555861] batch: 280  d_loss: 0.164294  g_loss: 6.499913\n",
      "Elapsed [2:36:56.922904] batch: 320  d_loss: 0.163066  g_loss: 6.254817\n",
      "Elapsed [2:37:15.057070] batch: 360  d_loss: 0.164582  g_loss: 6.103508\n",
      "Time taken for epoch: 175.372 secs\n",
      "\n",
      "Epoch: 54\n",
      "Elapsed [2:37:44.810965] batch: 40  d_loss: 0.163853  g_loss: 6.469375\n",
      "Elapsed [2:38:03.139263] batch: 80  d_loss: 0.171931  g_loss: 6.903335\n",
      "Elapsed [2:38:21.633381] batch: 120  d_loss: 0.169715  g_loss: 5.353324\n",
      "Elapsed [2:38:39.041391] batch: 160  d_loss: 0.181232  g_loss: 3.806347\n",
      "Elapsed [2:38:57.380456] batch: 200  d_loss: 0.165070  g_loss: 5.042376\n",
      "Elapsed [2:39:14.604691] batch: 240  d_loss: 0.171047  g_loss: 5.591049\n",
      "Elapsed [2:39:31.873782] batch: 280  d_loss: 0.166224  g_loss: 4.977286\n",
      "Elapsed [2:39:50.709989] batch: 320  d_loss: 0.165313  g_loss: 6.086290\n",
      "Elapsed [2:40:08.841639] batch: 360  d_loss: 0.163134  g_loss: 7.082065\n",
      "Time taken for epoch: 175.116 secs\n",
      "\n",
      "Epoch: 55\n",
      "Elapsed [2:40:40.433453] batch: 40  d_loss: 0.183841  g_loss: 4.072140\n",
      "Elapsed [2:40:58.223140] batch: 80  d_loss: 0.182632  g_loss: 4.583097\n",
      "Elapsed [2:41:15.996789] batch: 120  d_loss: 0.173588  g_loss: 4.831240\n",
      "Elapsed [2:41:34.116158] batch: 160  d_loss: 0.182776  g_loss: 3.660353\n",
      "Elapsed [2:41:52.447370] batch: 200  d_loss: 0.418245  g_loss: 1.940780\n",
      "Elapsed [2:42:10.732459] batch: 240  d_loss: 0.165549  g_loss: 5.137160\n",
      "Elapsed [2:42:28.664156] batch: 280  d_loss: 0.165359  g_loss: 4.829854\n",
      "Elapsed [2:42:47.163877] batch: 320  d_loss: 0.203481  g_loss: 4.565600\n",
      "Elapsed [2:43:05.067587] batch: 360  d_loss: 0.168028  g_loss: 4.871239\n",
      "Time taken for epoch: 174.999 secs\n",
      "\n",
      "Epoch: 56\n",
      "Elapsed [2:43:35.285872] batch: 40  d_loss: 0.172349  g_loss: 4.098099\n",
      "Elapsed [2:43:54.463215] batch: 80  d_loss: 0.204008  g_loss: 3.729968\n",
      "Elapsed [2:44:11.799886] batch: 120  d_loss: 0.165301  g_loss: 8.077705\n",
      "Elapsed [2:44:30.184755] batch: 160  d_loss: 0.205724  g_loss: 5.024626\n",
      "Elapsed [2:44:48.894851] batch: 200  d_loss: 0.170965  g_loss: 5.562254\n",
      "Elapsed [2:45:06.667328] batch: 240  d_loss: 0.164986  g_loss: 4.940901\n",
      "Elapsed [2:45:25.190005] batch: 280  d_loss: 0.168780  g_loss: 6.577942\n",
      "Elapsed [2:45:42.687629] batch: 320  d_loss: 0.165544  g_loss: 6.484184\n",
      "Elapsed [2:46:00.404582] batch: 360  d_loss: 0.165652  g_loss: 5.275902\n",
      "Time taken for epoch: 175.685 secs\n",
      "\n",
      "Epoch: 57\n",
      "Elapsed [2:46:31.247331] batch: 40  d_loss: 0.164476  g_loss: 6.138768\n",
      "Elapsed [2:46:49.741253] batch: 80  d_loss: 0.181011  g_loss: 5.157707\n",
      "Elapsed [2:47:08.170139] batch: 120  d_loss: 0.167091  g_loss: 4.936683\n",
      "Elapsed [2:47:25.537607] batch: 160  d_loss: 0.183925  g_loss: 5.236335\n",
      "Elapsed [2:47:43.394759] batch: 200  d_loss: 0.180645  g_loss: 4.068458\n",
      "Elapsed [2:48:01.678669] batch: 240  d_loss: 0.167288  g_loss: 4.604359\n",
      "Elapsed [2:48:19.750673] batch: 280  d_loss: 0.174105  g_loss: 5.114791\n",
      "Elapsed [2:48:37.434689] batch: 320  d_loss: 0.166838  g_loss: 4.810719\n",
      "Elapsed [2:48:55.284678] batch: 360  d_loss: 0.167226  g_loss: 4.925605\n",
      "Time taken for epoch: 175.205 secs\n",
      "\n",
      "Epoch: 58\n",
      "Elapsed [2:49:25.152374] batch: 40  d_loss: 0.164457  g_loss: 5.929044\n",
      "Elapsed [2:49:43.666444] batch: 80  d_loss: 0.168924  g_loss: 4.570206\n",
      "Elapsed [2:50:01.740257] batch: 120  d_loss: 0.172765  g_loss: 4.887928\n",
      "Elapsed [2:50:20.289420] batch: 160  d_loss: 0.175312  g_loss: 4.904206\n",
      "Elapsed [2:50:38.133050] batch: 200  d_loss: 0.174049  g_loss: 7.393225\n",
      "Elapsed [2:50:57.464133] batch: 240  d_loss: 0.170471  g_loss: 4.299687\n",
      "Elapsed [2:51:15.717481] batch: 280  d_loss: 0.168139  g_loss: 4.431077\n",
      "Elapsed [2:51:33.784037] batch: 320  d_loss: 0.167823  g_loss: 4.736811\n",
      "Elapsed [2:51:51.690214] batch: 360  d_loss: 0.172449  g_loss: 3.897937\n",
      "Time taken for epoch: 175.533 secs\n",
      "\n",
      "Epoch: 59\n",
      "Elapsed [2:52:22.120357] batch: 40  d_loss: 0.189183  g_loss: 4.083040\n",
      "Elapsed [2:52:39.749799] batch: 80  d_loss: 0.170171  g_loss: 6.353976\n",
      "Elapsed [2:52:57.888853] batch: 120  d_loss: 0.164230  g_loss: 5.911830\n",
      "Elapsed [2:53:15.735294] batch: 160  d_loss: 0.179965  g_loss: 5.638041\n",
      "Elapsed [2:53:33.255697] batch: 200  d_loss: 0.174058  g_loss: 5.234034\n",
      "Elapsed [2:53:51.274467] batch: 240  d_loss: 0.168246  g_loss: 6.770123\n",
      "Elapsed [2:54:09.684021] batch: 280  d_loss: 0.165580  g_loss: 4.815547\n",
      "Elapsed [2:54:28.751236] batch: 320  d_loss: 0.169796  g_loss: 7.080552\n",
      "Elapsed [2:54:46.599748] batch: 360  d_loss: 0.174264  g_loss: 5.318532\n",
      "Time taken for epoch: 174.920 secs\n",
      "\n",
      "Epoch: 60\n",
      "Elapsed [2:55:16.093523] batch: 40  d_loss: 0.181866  g_loss: 3.981002\n",
      "Elapsed [2:55:35.396690] batch: 80  d_loss: 0.174457  g_loss: 3.984278\n",
      "Elapsed [2:55:53.101058] batch: 120  d_loss: 0.166811  g_loss: 7.672834\n",
      "Elapsed [2:56:10.828522] batch: 160  d_loss: 0.164117  g_loss: 6.987251\n",
      "Elapsed [2:56:28.556828] batch: 200  d_loss: 0.165164  g_loss: 6.673622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed [2:56:46.747296] batch: 240  d_loss: 0.233542  g_loss: 3.166710\n",
      "Elapsed [2:57:04.615453] batch: 280  d_loss: 0.164116  g_loss: 5.263212\n",
      "Elapsed [2:57:22.489645] batch: 320  d_loss: 0.164101  g_loss: 5.731289\n",
      "Elapsed [2:57:40.454905] batch: 360  d_loss: 0.165701  g_loss: 4.686019\n",
      "Time taken for epoch: 175.121 secs\n",
      "\n",
      "Epoch: 61\n",
      "Elapsed [2:58:15.178889] batch: 40  d_loss: 0.169819  g_loss: 6.556722\n",
      "Elapsed [2:58:33.341947] batch: 80  d_loss: 0.201070  g_loss: 5.598119\n",
      "Elapsed [2:58:52.021929] batch: 120  d_loss: 0.192641  g_loss: 3.629164\n",
      "Elapsed [2:59:10.102599] batch: 160  d_loss: 0.197505  g_loss: 3.989800\n",
      "Elapsed [2:59:28.253284] batch: 200  d_loss: 0.169635  g_loss: 5.509024\n",
      "Elapsed [2:59:46.333289] batch: 240  d_loss: 0.163211  g_loss: 7.211070\n",
      "Elapsed [3:00:04.623969] batch: 280  d_loss: 0.163403  g_loss: 6.906624\n",
      "Elapsed [3:00:22.542720] batch: 320  d_loss: 0.167490  g_loss: 7.091652\n",
      "Elapsed [3:00:40.567391] batch: 360  d_loss: 0.165355  g_loss: 5.558391\n",
      "Time taken for epoch: 175.340 secs\n",
      "\n",
      "Epoch: 62\n",
      "Elapsed [3:01:10.223427] batch: 40  d_loss: 0.164903  g_loss: 5.002324\n",
      "Elapsed [3:01:27.617564] batch: 80  d_loss: 0.163936  g_loss: 5.419057\n",
      "Elapsed [3:01:45.233442] batch: 120  d_loss: 0.162952  g_loss: 6.521176\n",
      "Elapsed [3:02:03.176671] batch: 160  d_loss: 0.166943  g_loss: 7.224995\n",
      "Elapsed [3:02:20.781570] batch: 200  d_loss: 0.185401  g_loss: 7.112532\n",
      "Elapsed [3:02:39.284203] batch: 240  d_loss: 1.373521  g_loss: 4.280031\n",
      "Elapsed [3:02:57.500235] batch: 280  d_loss: 0.184319  g_loss: 4.896120\n",
      "Elapsed [3:03:15.620468] batch: 320  d_loss: 0.166245  g_loss: 4.949355\n",
      "Elapsed [3:03:34.810652] batch: 360  d_loss: 0.164681  g_loss: 8.282290\n",
      "Time taken for epoch: 174.775 secs\n",
      "\n",
      "Epoch: 63\n",
      "Elapsed [3:04:04.845053] batch: 40  d_loss: 0.172900  g_loss: 4.136860\n",
      "Elapsed [3:04:23.548634] batch: 80  d_loss: 0.165869  g_loss: 5.677143\n",
      "Elapsed [3:04:41.448703] batch: 120  d_loss: 0.164254  g_loss: 7.334303\n",
      "Elapsed [3:04:59.945448] batch: 160  d_loss: 0.164552  g_loss: 6.375156\n",
      "Elapsed [3:05:17.534998] batch: 200  d_loss: 0.200839  g_loss: 3.448281\n",
      "Elapsed [3:05:36.112618] batch: 240  d_loss: 0.178357  g_loss: 4.585776\n",
      "Elapsed [3:05:53.806900] batch: 280  d_loss: 0.167069  g_loss: 5.718364\n",
      "Elapsed [3:06:11.586064] batch: 320  d_loss: 0.163718  g_loss: 5.932571\n",
      "Elapsed [3:06:29.803578] batch: 360  d_loss: 0.168844  g_loss: 7.021531\n",
      "Time taken for epoch: 174.895 secs\n",
      "\n",
      "Epoch: 64\n",
      "Elapsed [3:07:00.252532] batch: 40  d_loss: 0.165256  g_loss: 6.310586\n",
      "Elapsed [3:07:18.434044] batch: 80  d_loss: 0.184985  g_loss: 5.517907\n",
      "Elapsed [3:07:36.866276] batch: 120  d_loss: 0.163237  g_loss: 7.672767\n",
      "Elapsed [3:07:55.178430] batch: 160  d_loss: 0.163081  g_loss: 6.273438\n",
      "Elapsed [3:08:12.605675] batch: 200  d_loss: 0.188160  g_loss: 6.607416\n",
      "Elapsed [3:08:31.304374] batch: 240  d_loss: 0.168072  g_loss: 5.499599\n",
      "Elapsed [3:08:48.985754] batch: 280  d_loss: 0.163655  g_loss: 6.500690\n",
      "Elapsed [3:09:07.530730] batch: 320  d_loss: 0.170635  g_loss: 5.144026\n",
      "Elapsed [3:09:24.963773] batch: 360  d_loss: 0.165907  g_loss: 4.991129\n",
      "Time taken for epoch: 174.740 secs\n",
      "\n",
      "Epoch: 65\n",
      "Elapsed [3:09:54.564843] batch: 40  d_loss: 0.184793  g_loss: 6.547365\n",
      "Elapsed [3:10:13.280836] batch: 80  d_loss: 0.166759  g_loss: 5.536302\n",
      "Elapsed [3:10:30.938182] batch: 120  d_loss: 0.164867  g_loss: 5.644293\n",
      "Elapsed [3:10:49.575647] batch: 160  d_loss: 0.165030  g_loss: 5.262967\n",
      "Elapsed [3:11:07.868806] batch: 200  d_loss: 0.191672  g_loss: 5.653182\n",
      "Elapsed [3:11:26.117239] batch: 240  d_loss: 0.323564  g_loss: 8.142283\n",
      "Elapsed [3:11:43.770615] batch: 280  d_loss: 0.163013  g_loss: 6.439101\n",
      "Elapsed [3:12:01.546392] batch: 320  d_loss: 0.164132  g_loss: 5.758751\n",
      "Elapsed [3:12:19.599429] batch: 360  d_loss: 0.223123  g_loss: 3.832045\n",
      "Time taken for epoch: 174.730 secs\n",
      "\n",
      "Epoch: 66\n",
      "Elapsed [3:12:49.545178] batch: 40  d_loss: 0.175837  g_loss: 4.163671\n",
      "Elapsed [3:13:07.461481] batch: 80  d_loss: 0.165237  g_loss: 4.908815\n",
      "Elapsed [3:13:25.339010] batch: 120  d_loss: 0.167887  g_loss: 5.543657\n",
      "Elapsed [3:13:43.782408] batch: 160  d_loss: 0.165740  g_loss: 4.828403\n",
      "Elapsed [3:14:01.424896] batch: 200  d_loss: 0.162955  g_loss: 7.199428\n",
      "Elapsed [3:14:19.299612] batch: 240  d_loss: 0.172737  g_loss: 5.601184\n",
      "Elapsed [3:14:37.118309] batch: 280  d_loss: 0.166574  g_loss: 5.718285\n",
      "Elapsed [3:14:55.177630] batch: 320  d_loss: 0.164617  g_loss: 5.162235\n",
      "Elapsed [3:15:13.406256] batch: 360  d_loss: 0.163649  g_loss: 6.156026\n",
      "Time taken for epoch: 174.687 secs\n",
      "\n",
      "Epoch: 67\n",
      "Elapsed [3:15:44.772910] batch: 40  d_loss: 0.165946  g_loss: 4.998528\n",
      "Elapsed [3:16:02.009175] batch: 80  d_loss: 0.164527  g_loss: 5.288787\n",
      "Elapsed [3:16:20.382283] batch: 120  d_loss: 0.167494  g_loss: 5.848562\n",
      "Elapsed [3:16:39.180332] batch: 160  d_loss: 0.188166  g_loss: 5.614504\n",
      "Elapsed [3:16:57.267375] batch: 200  d_loss: 0.163634  g_loss: 7.688239\n",
      "Elapsed [3:17:14.727152] batch: 240  d_loss: 0.174336  g_loss: 5.021058\n",
      "Elapsed [3:17:32.194456] batch: 280  d_loss: 0.163310  g_loss: 6.161884\n",
      "Elapsed [3:17:49.936356] batch: 320  d_loss: 0.163196  g_loss: 6.109463\n",
      "Elapsed [3:18:09.221867] batch: 360  d_loss: 0.220865  g_loss: 5.164747\n",
      "Time taken for epoch: 174.908 secs\n",
      "\n",
      "Epoch: 68\n",
      "Elapsed [3:18:39.543036] batch: 40  d_loss: 0.164500  g_loss: 5.437665\n",
      "Elapsed [3:18:58.540633] batch: 80  d_loss: 0.163490  g_loss: 6.725726\n",
      "Elapsed [3:19:16.438400] batch: 120  d_loss: 0.165513  g_loss: 5.660254\n",
      "Elapsed [3:19:34.797543] batch: 160  d_loss: 0.167140  g_loss: 5.975051\n",
      "Elapsed [3:19:52.738932] batch: 200  d_loss: 0.169835  g_loss: 4.685659\n",
      "Elapsed [3:20:10.706982] batch: 240  d_loss: 0.167138  g_loss: 5.022471\n",
      "Elapsed [3:20:27.949280] batch: 280  d_loss: 0.164510  g_loss: 5.364768\n",
      "Elapsed [3:20:45.804770] batch: 320  d_loss: 0.166395  g_loss: 5.580795\n",
      "Elapsed [3:21:04.193764] batch: 360  d_loss: 0.164236  g_loss: 6.649604\n",
      "Time taken for epoch: 174.800 secs\n",
      "\n",
      "Epoch: 69\n",
      "Elapsed [3:21:33.762836] batch: 40  d_loss: 0.169288  g_loss: 8.210169\n",
      "Elapsed [3:21:51.927880] batch: 80  d_loss: 0.164596  g_loss: 5.986501\n",
      "Elapsed [3:22:10.045060] batch: 120  d_loss: 0.165545  g_loss: 6.057205\n",
      "Elapsed [3:22:28.867482] batch: 160  d_loss: 0.176137  g_loss: 3.981988\n",
      "Elapsed [3:22:47.518283] batch: 200  d_loss: 0.168611  g_loss: 5.312882\n",
      "Elapsed [3:23:05.486855] batch: 240  d_loss: 0.181816  g_loss: 3.857938\n",
      "Elapsed [3:23:22.904132] batch: 280  d_loss: 0.170501  g_loss: 4.251225\n",
      "Elapsed [3:23:40.758285] batch: 320  d_loss: 0.163268  g_loss: 6.766102\n",
      "Elapsed [3:23:59.059750] batch: 360  d_loss: 0.173885  g_loss: 4.618859\n",
      "Time taken for epoch: 174.735 secs\n",
      "\n",
      "Epoch: 70\n",
      "Elapsed [3:24:28.370990] batch: 40  d_loss: 0.165763  g_loss: 6.283238\n",
      "Elapsed [3:24:45.962264] batch: 80  d_loss: 0.223472  g_loss: 3.862044\n",
      "Elapsed [3:25:04.862850] batch: 120  d_loss: 0.171572  g_loss: 5.222945\n",
      "Elapsed [3:25:23.746958] batch: 160  d_loss: 0.169650  g_loss: 6.224432\n",
      "Elapsed [3:25:41.807664] batch: 200  d_loss: 0.177312  g_loss: 6.679330\n",
      "Elapsed [3:25:59.188364] batch: 240  d_loss: 0.186256  g_loss: 4.182340\n",
      "Elapsed [3:26:17.500510] batch: 280  d_loss: 0.208416  g_loss: 10.965075\n",
      "Elapsed [3:26:35.295771] batch: 320  d_loss: 0.175131  g_loss: 3.866012\n",
      "Elapsed [3:26:53.913136] batch: 360  d_loss: 0.168898  g_loss: 4.556409\n",
      "Time taken for epoch: 175.053 secs\n",
      "\n",
      "Epoch: 71\n",
      "Elapsed [3:27:26.401619] batch: 40  d_loss: 0.163140  g_loss: 6.314543\n",
      "Elapsed [3:27:44.751562] batch: 80  d_loss: 0.183987  g_loss: 6.519436\n",
      "Elapsed [3:28:03.194170] batch: 120  d_loss: 0.172285  g_loss: 5.996529\n",
      "Elapsed [3:28:22.499616] batch: 160  d_loss: 0.176702  g_loss: 4.143141\n",
      "Elapsed [3:28:40.441172] batch: 200  d_loss: 0.164366  g_loss: 5.228294\n",
      "Elapsed [3:28:57.792245] batch: 240  d_loss: 0.164897  g_loss: 4.992725\n",
      "Elapsed [3:29:15.825197] batch: 280  d_loss: 0.173908  g_loss: 4.279846\n",
      "Elapsed [3:29:33.195453] batch: 320  d_loss: 0.169639  g_loss: 6.324331\n",
      "Elapsed [3:29:50.860356] batch: 360  d_loss: 0.163417  g_loss: 6.130891\n",
      "Time taken for epoch: 175.140 secs\n",
      "\n",
      "Epoch: 72\n",
      "Elapsed [3:30:20.500567] batch: 40  d_loss: 0.166725  g_loss: 5.820216\n",
      "Elapsed [3:30:38.217590] batch: 80  d_loss: 0.162855  g_loss: 6.917716\n",
      "Elapsed [3:30:55.954606] batch: 120  d_loss: 0.166485  g_loss: 4.581481\n",
      "Elapsed [3:31:14.373740] batch: 160  d_loss: 0.167085  g_loss: 5.909392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed [3:31:32.420704] batch: 200  d_loss: 0.163163  g_loss: 6.178625\n",
      "Elapsed [3:31:50.475881] batch: 240  d_loss: 0.201301  g_loss: 5.836020\n",
      "Elapsed [3:32:09.877189] batch: 280  d_loss: 0.186203  g_loss: 3.385997\n",
      "Elapsed [3:32:28.230055] batch: 320  d_loss: 0.167802  g_loss: 4.813329\n",
      "Elapsed [3:32:46.106406] batch: 360  d_loss: 0.197114  g_loss: 3.994420\n",
      "Time taken for epoch: 175.059 secs\n",
      "\n",
      "Epoch: 73\n",
      "Elapsed [3:33:16.426260] batch: 40  d_loss: 0.178640  g_loss: 4.034286\n",
      "Elapsed [3:33:34.239053] batch: 80  d_loss: 0.164269  g_loss: 5.730256\n",
      "Elapsed [3:33:52.236186] batch: 120  d_loss: 0.164031  g_loss: 5.778656\n",
      "Elapsed [3:34:10.414613] batch: 160  d_loss: 0.164073  g_loss: 5.604185\n",
      "Elapsed [3:34:29.183065] batch: 200  d_loss: 0.168527  g_loss: 8.590828\n",
      "Elapsed [3:34:47.802456] batch: 240  d_loss: 0.162733  g_loss: 7.995696\n",
      "Elapsed [3:35:05.913580] batch: 280  d_loss: 0.171855  g_loss: 4.442997\n",
      "Elapsed [3:35:23.462626] batch: 320  d_loss: 0.165977  g_loss: 4.633571\n",
      "Elapsed [3:35:41.868096] batch: 360  d_loss: 0.219874  g_loss: 3.873045\n",
      "Time taken for epoch: 175.481 secs\n",
      "\n",
      "Epoch: 74\n",
      "Elapsed [3:36:12.100836] batch: 40  d_loss: 0.182172  g_loss: 4.071710\n",
      "Elapsed [3:36:29.443112] batch: 80  d_loss: 0.165111  g_loss: 9.004648\n",
      "Elapsed [3:36:47.074165] batch: 120  d_loss: 0.164577  g_loss: 5.902120\n",
      "Elapsed [3:37:04.875852] batch: 160  d_loss: 0.182326  g_loss: 3.344225\n",
      "Elapsed [3:37:24.057370] batch: 200  d_loss: 0.163037  g_loss: 9.540574\n",
      "Elapsed [3:37:42.333248] batch: 240  d_loss: 0.164709  g_loss: 7.994465\n",
      "Elapsed [3:38:00.111481] batch: 280  d_loss: 0.163362  g_loss: 6.440607\n",
      "Elapsed [3:38:17.927595] batch: 320  d_loss: 0.166310  g_loss: 5.682474\n",
      "Elapsed [3:38:35.569637] batch: 360  d_loss: 0.226898  g_loss: 3.980249\n",
      "Time taken for epoch: 174.776 secs\n",
      "\n",
      "Epoch: 75\n",
      "Elapsed [3:39:06.048453] batch: 40  d_loss: 0.164430  g_loss: 7.750950\n",
      "Elapsed [3:39:24.622408] batch: 80  d_loss: 0.165896  g_loss: 5.298415\n",
      "Elapsed [3:39:42.986469] batch: 120  d_loss: 0.177340  g_loss: 4.915742\n",
      "Elapsed [3:40:00.940841] batch: 160  d_loss: 0.208444  g_loss: 3.246556\n",
      "Elapsed [3:40:20.145495] batch: 200  d_loss: 0.167332  g_loss: 4.919470\n",
      "Elapsed [3:40:41.042780] batch: 240  d_loss: 0.162988  g_loss: 6.635669\n",
      "Elapsed [3:41:01.179138] batch: 280  d_loss: 0.181159  g_loss: 6.705062\n",
      "Elapsed [3:41:20.135561] batch: 320  d_loss: 0.191402  g_loss: 4.106983\n",
      "Elapsed [3:41:37.994725] batch: 360  d_loss: 0.236610  g_loss: 4.894073\n",
      "Time taken for epoch: 182.320 secs\n",
      "\n",
      "Epoch: 76\n",
      "Elapsed [3:42:09.803746] batch: 40  d_loss: 0.167327  g_loss: 5.341176\n",
      "Elapsed [3:42:28.341934] batch: 80  d_loss: 0.163074  g_loss: 16.137192\n",
      "Elapsed [3:42:46.386913] batch: 120  d_loss: 0.171458  g_loss: 5.768041\n",
      "Elapsed [3:43:04.553599] batch: 160  d_loss: 0.176721  g_loss: 4.211368\n",
      "Elapsed [3:43:21.910531] batch: 200  d_loss: 0.168982  g_loss: 4.958455\n",
      "Elapsed [3:43:40.428730] batch: 240  d_loss: 0.475987  g_loss: 0.893864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9be5e9e55a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTART_EPOCH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTOTAL_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/sunset-gan/msg-gan/MSG_GAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, gen_optim, dis_optim, loss_fn, normalize_latents, start, num_epochs, checkpoint_factor, feedback_factor)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0;31m# optimize the generator:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 gen_loss = self.optimize_generator(gen_optim, gan_input,\n\u001b[0m\u001b[1;32m    378\u001b[0m                                                    images, loss_fn)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sunset-gan/msg-gan/MSG_GAN.py\u001b[0m in \u001b[0;36moptimize_generator\u001b[0;34m(self, gen_optim, noise, real_batch, loss_fn)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_shadow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     def train(self, data, gen_optim, dis_optim, loss_fn, normalize_latents=True,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss = StandardGAN(model.dis, real_label=0.9)\n",
    "model.train(dataloader, g_optim, d_optim, loss, start=START_EPOCH+1, num_epochs=TOTAL_EPOCH, checkpoint_factor=10, feedback_factor=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
